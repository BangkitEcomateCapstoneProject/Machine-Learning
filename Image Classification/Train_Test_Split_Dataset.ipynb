{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23kIdtyh_Cv-",
        "outputId": "a1c03f40-8cc7-4a4b-fd1c-fc88df2d394a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDIqKpS6-zP6",
        "outputId": "fb1252ed-988f-46ff-e4ba-8bd76812f46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing biological - train: 100%|██████████| 788/788 [00:33<00:00, 23.50it/s]\n",
            "Processing biological - val: 100%|██████████| 197/197 [00:03<00:00, 55.09it/s]\n",
            "Processing plastic - train: 100%|██████████| 800/800 [00:35<00:00, 22.85it/s]\n",
            "Processing plastic - val: 100%|██████████| 200/200 [00:03<00:00, 50.10it/s]\n",
            "Processing metal - train: 100%|██████████| 800/800 [00:56<00:00, 14.09it/s]\n",
            "Processing metal - val: 100%|██████████| 200/200 [00:03<00:00, 59.10it/s]\n",
            "Processing trash - train: 100%|██████████| 667/667 [00:43<00:00, 15.38it/s]\n",
            "Processing trash - val: 100%|██████████| 167/167 [00:02<00:00, 59.67it/s]\n",
            "Processing paper - train: 100%|██████████| 800/800 [00:35<00:00, 22.45it/s]\n",
            "Processing paper - val: 100%|██████████| 200/200 [00:03<00:00, 50.29it/s]\n",
            "Processing glass - train: 100%|██████████| 800/800 [00:59<00:00, 13.48it/s]\n",
            "Processing glass - val: 100%|██████████| 200/200 [00:03<00:00, 53.52it/s]\n",
            "Processing cardboard - train: 100%|██████████| 800/800 [00:34<00:00, 23.09it/s]\n",
            "Processing cardboard - val: 100%|██████████| 200/200 [00:03<00:00, 64.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split and copied successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set the paths\n",
        "source_dir = '/content/drive/MyDrive/datasetv2'  # Change to your source directory\n",
        "train_dir = '/content/drive/MyDrive/data/train'\n",
        "val_dir = '/content/drive/MyDrive/data/val'\n",
        "split_ratio = 0.8  # Ratio for training data\n",
        "\n",
        "# Ensure directories exist\n",
        "Path(train_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(val_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Iterate over each class in the source directory\n",
        "for class_name in os.listdir(source_dir):\n",
        "    class_dir = os.path.join(source_dir, class_name)\n",
        "\n",
        "    if not os.path.isdir(class_dir):\n",
        "        continue\n",
        "\n",
        "    # Create class directories in train and val folders\n",
        "    Path(os.path.join(train_dir, class_name)).mkdir(parents=True, exist_ok=True)\n",
        "    Path(os.path.join(val_dir, class_name)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # List all files in the class directory\n",
        "    files = os.listdir(class_dir)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    # Split the files into training and validation sets\n",
        "    split_index = int(len(files) * split_ratio)\n",
        "    train_files = files[:split_index]\n",
        "    val_files = files[split_index:]\n",
        "\n",
        "    # Copy files to the respective directories\n",
        "    for file_name in tqdm(train_files, desc=f\"Processing {class_name} - train\"):\n",
        "        src_file = os.path.join(class_dir, file_name)\n",
        "        dst_file = os.path.join(train_dir, class_name, file_name)\n",
        "        shutil.copy2(src_file, dst_file)\n",
        "\n",
        "    for file_name in tqdm(val_files, desc=f\"Processing {class_name} - val\"):\n",
        "        src_file = os.path.join(class_dir, file_name)\n",
        "        dst_file = os.path.join(val_dir, class_name, file_name)\n",
        "        shutil.copy2(src_file, dst_file)\n",
        "\n",
        "print(\"Dataset split and copied successfully.\")\n"
      ]
    }
  ]
}